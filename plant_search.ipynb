<a target="_blank" href="https://colab.research.google.com/github/GithubUser017/EntrezPlantSearch/blob/main/plant_search.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive # mount google drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "x76S5KVkoJbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Bio # install Bio package\n"
      ],
      "metadata": {
        "id": "TDpKxoSC9G88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional Code Block - Save Email and/or search choice for multiple searches\n",
        "# If this block is run atleast once, the search script will not ask for your email or search choice\n",
        "# NCBI requires email, so make sure you are inputting your email to keep from being blocked from their server.\n",
        "\n",
        "#Enter email inside the single quote marks below\n",
        "\n",
        "email = 'Enter email here (Do not delete single quotes)'\n",
        "\n",
        "if '@' in email:\n",
        "  emailer = 1\n",
        "else:\n",
        "  emailer = 0\n",
        "\n",
        "# Enter Search Choice after the equals sign below\n",
        "\n",
        "choice = ''\n",
        "try:\n",
        "  if int(choice) > 0 & int(choice) < 5:\n",
        "    choicer = 1\n",
        "  else:\n",
        "    choicer = 0\n",
        "except:\n",
        "  print('No Search Choice Selected, You can select later')\n",
        "  choicer = 0\n",
        "\n",
        "# Note Choices: 1 - plant genera | 2 - phytochemicals | 3 - Both (Slow)| 4 - Human Protein Coding Genes (inferior to MESH)"
      ],
      "metadata": {
        "id": "MOE0qQr7UFt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from Bio import Entrez\n",
        "import datetime\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "from http.client import IncompleteRead\n",
        "\n",
        "try:\n",
        "  emailer\n",
        "  if emailer != 1:\n",
        "    email = input('Please enter your email: ')\n",
        "except:\n",
        "  email = input('Please enter your email: ')\n",
        "\n",
        "# Email address is required by NCBI\n",
        "Entrez.email = email\n",
        "\n",
        "# Choose which txt files to search over\n",
        "try:\n",
        "  choicer  \n",
        "  if choicer != 1: \n",
        "    choice = input('Do you want to search over all plant genera (enter 1) \\n \\\n",
        "                      | all phytochemicals (enter 2) | or both (enter 3) | \\n \\\n",
        "                      If you do not want to search over plants or phytochemicals, \\n \\\n",
        "                      try searching over human genes first (not as good as MESH term search) (enter 4) : ')\n",
        "except:\n",
        "  choice = input('Do you want to search over all plant genera (enter 1) \\n \\\n",
        "                    | all phytochemicals (enter 2) | or both (enter 3) | \\n \\\n",
        "                    If you do not want to search over plants or phytochemicals, \\n \\\n",
        "                    try searching over human genes first (not as good as MESH term search) (enter 4) : ')\n",
        "\n",
        "choice = int(choice)\n",
        "\n",
        "# Load correct text file\n",
        "if choice == 1:\n",
        "    with open('drive/MyDrive/plant_search_text_files/genus_names2.txt', 'r') as f:\n",
        "        genus_names = f.read().split('@')\n",
        "if choice == 2:\n",
        "    with open('drive/MyDrive/plant_search_text_files/phytochem3.txt', 'r') as f:\n",
        "        genus_names = f.read().split('\\t')\n",
        "       \n",
        "if choice == 3:\n",
        "    with open('drive/MyDrive/plant_search_text_files/genus_names2.txt', 'r') as f:\n",
        "        genus_names = f.read().split('@')\n",
        "    with open('drive/MyDrive/plant_search_text_files/phytochem3.txt', 'r') as f:\n",
        "        phyt_names = f.read().split('\\t')\n",
        "\n",
        "if choice == 4:\n",
        "    with open('drive/MyDrive/plant_search_text_files/gene1.txt', 'r') as f:\n",
        "        genus_names = f.read().split('@')\n",
        "\n",
        "\n",
        "# User-defined search term\n",
        "user_query = input('Enter additional non-plant search terms: ')\n",
        "\n",
        "# Set counter in case choice == 3. This allows first 38 searches to include \"plant\" as a key word\n",
        "gen_phyt_counter = 1\n",
        "\n",
        "# Create directory for input files if it doesn't exist\n",
        "if not os.path.exists('input_files'):\n",
        "    os.makedirs('input_files')\n",
        "\n",
        "# Split the genus names into groups of 1000 or less, to stay under the PubMed search limit\n",
        "genus_groups = [genus_names[i:i+1000] for i in range(0, len(genus_names), 1000)]\n",
        "\n",
        "if choice == 3:\n",
        "    genus_groups = [genus_names[i:i+1000] for i in range(0, len(genus_names), 1000)]\n",
        "    phyt_groups = [phyt_names[i:i+1000] for i in range(0, len(phyt_names), 1000)]\n",
        "\n",
        "    genus_groups = genus_groups + phyt_groups\n",
        "   \n",
        "\n",
        "\n",
        "# List to store abstracts and their associated date information\n",
        "abstracts_with_info = []\n",
        "article_title = []\n",
        "\n",
        "# Set to keep track of seen Pubmed IDs\n",
        "seen_pmids = set()\n",
        "\n",
        "for i, genus_group in enumerate(genus_groups):\n",
        "    # Construct query string\n",
        "    if choice == 1: \n",
        "        query_terms = '(' + ' OR '.join(genus_group) + ') + AND \"plant\" AND ' + user_query\n",
        "    if choice == 3: \n",
        "        if gen_phyt_counter <= 38:\n",
        "            query_terms = '(' + ' OR '.join(genus_group) + ') + AND \"plant\" AND ' + user_query\n",
        "        if gen_phyt_counter > 38:\n",
        "            query_terms = '(' + ' OR '.join(genus_group) + ') + AND ' + user_query \n",
        "    if choice == 2: \n",
        "        query_terms = '(' + ' OR '.join(genus_group) + ') + AND ' + user_query \n",
        "    if choice == 4: \n",
        "        query_terms = '(' + ' OR '.join(genus_group) + ') + AND \"gene\" AND ' + user_query\n",
        "    \n",
        "    gen_phyt_counter += 1\n",
        "    \n",
        "    # # # testing line, remove\n",
        "    # if gen_phyt_counter == 38:\n",
        "    #     print(query_terms)\n",
        "    # if gen_phyt_counter == 39:\n",
        "    #     print(query_terms)\n",
        "    # if gen_phyt_counter == 40:\n",
        "    #     print(query_terms)\n",
        "\n",
        "\n",
        "    # Print search query\n",
        "    print(f'Searching group {i+1}/{len(genus_groups)}')\n",
        "\n",
        "    \n",
        "    # Perform search\n",
        "    herror = 0\n",
        "    error_number = 0\n",
        "    while herror == 0:\n",
        "      try:\n",
        "          handle = Entrez.esearch(db='pubmed', term=query_terms, retmax=100000)\n",
        "          record = Entrez.read(handle)\n",
        "          handle.close()\n",
        "          herror = 1\n",
        "      except Exception as err:\n",
        "          error_number += 1\n",
        "          if error_number == 5:\n",
        "            raise err\n",
        "          print(f\"Error: {str(err)}. Retrying in 5 seconds...\")\n",
        "          time.sleep(5)\n",
        "          herror = 0\n",
        "        \n",
        "\n",
        "    # Fetch abstracts for all search results\n",
        "    id_list = record['IdList']\n",
        "    \n",
        "    query_numb = 1\n",
        "    exc = 1\n",
        "    \n",
        "    if id_list:\n",
        "      while exc == 1:\n",
        "        try:\n",
        "          print(f'Fetching {len(id_list)} abstracts...')\n",
        "          handle = Entrez.efetch(db='pubmed', id=id_list, retmode='xml')\n",
        "          records = Entrez.read(handle)\n",
        "          handle.close()\n",
        "          exc = 0\n",
        "\n",
        "        # commented out lines below still allow for http error\n",
        "        # except IncompleteRead: \n",
        "        #   query_numb += 1\n",
        "        #   if query_numb == 5:\n",
        "        #     raise Exception('Failed to fetch abstracts after 5 attempts.')\n",
        "        #   print(f'Error fetching abstracts, retrying ({query_numb}/5)...')\n",
        "        #   time.sleep(5) # Wait 5 seconds before retrying\n",
        "        #   exc = 1\n",
        "        \n",
        "        except Exception as err:\n",
        "          query_numb += 1\n",
        "          if query_numb == 5:\n",
        "            raise err\n",
        "          print(f\"Error: {str(err)}. Retrying in 5 seconds...\")\n",
        "          time.sleep(5)\n",
        "          exc = 1\n",
        "          \n",
        "          \n",
        "          \n",
        "\n",
        "    # def fetch_abstracts(id_list):\n",
        "    #   for i in range(5): # Try up to 5 times\n",
        "    #       try:\n",
        "    #           print(f'Fetching {len(id_list)} abstracts...')\n",
        "    #           handle = Entrez.efetch(db='pubmed', id=id_list, retmode='xml')\n",
        "    #           records = Entrez.read(handle)\n",
        "    #           handle.close()\n",
        "    #           return records\n",
        "    #       except IncompleteRead:\n",
        "    #           print(f'Error fetching abstracts, retrying ({i+1}/5)...')\n",
        "    #           time.sleep(5) # Wait 5 seconds before retrying\n",
        "    #           raise Exception('Failed to fetch abstracts after 5 attempts.')\n",
        "\n",
        "    # fetch_abstracts(id_list)\n",
        "\n",
        "        # Extract abstracts and date information for each record\n",
        "        for record in records['PubmedArticle']:\n",
        "            try:\n",
        "                abstract = record['MedlineCitation']['Article']['Abstract']['AbstractText'][0]\n",
        "            except (KeyError, IndexError):\n",
        "                abstract = 'Not available'\n",
        "            #EntrezDate\n",
        "            try:\n",
        "                pub_date = record['MedlineCitation']['DateRevised']\n",
        "                pub_date_str = f\"{pub_date.get('Year', 'Not available')}-{pub_date.get('Month', 'Not available')}-{pub_date.get('Day', 'Not available')}\"\n",
        "            except KeyError:\n",
        "                pub_date_str = 'Not available'\n",
        "            #PubDate\n",
        "            try:\n",
        "                pub_date1 = record['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']\n",
        "                pub_date_str1 = f\"{pub_date1.get('Year', 'Not available')} {pub_date1.get('Month', 'Not available')}\"\n",
        "            except KeyError:\n",
        "                pub_date_str1 = 'Not available'\n",
        "            try:\n",
        "                journal = record['MedlineCitation']['Article']['Journal']['Title']\n",
        "            except KeyError:\n",
        "                journal = 'Not available'\n",
        "            try:\n",
        "                authors = record['MedlineCitation']['Article']['AuthorList']\n",
        "                author_names = [f\"{author.get('LastName', 'Not available')}, {author.get('ForeName', '')}\" for author in authors]\n",
        "                authors_str = ', '.join(author_names)\n",
        "            except KeyError:\n",
        "                authors_str = 'Not available'\n",
        "            try:\n",
        "                pmid = record['MedlineCitation']['PMID']\n",
        "            except KeyError:\n",
        "                pmid = 'Not available'\n",
        "            \n",
        "            #Add new PubMed ID to set\n",
        "            skipme=1\n",
        "            if pmid not in seen_pmids:\n",
        "                seen_pmids.add(pmid)\n",
        "                skipme=0\n",
        "\n",
        "            \n",
        "\n",
        "            Date1 = pub_date_str1[0:4]\n",
        "            Date0 = pub_date_str[0:4]\n",
        "\n",
        "            \n",
        "\n",
        "            if Date1 != Date0:\n",
        "                if \"Not\" in Date1:\n",
        "                    out_string = f\"{pub_date_str}  -DateCatalogued\\n{pub_date_str1} -DatePublished\\nAuthors: {authors_str}\\nJournal: {journal}\\nTitle: {record['MedlineCitation']['Article']['ArticleTitle']}\\nPMID: {pmid}\\nAbstract: {abstract}\\n\\n\"\n",
        "                    out_string2 = f\"{pub_date_str}  -DateCatalogued\\n{pub_date_str1} -DatePublished\\nTitle: {record['MedlineCitation']['Article']['ArticleTitle']}\"\n",
        "                else:\n",
        "                    if Date1 < Date0:\n",
        "                        out_string = f\"{pub_date_str1} -DatePublished\\n{pub_date_str}  -DateCatalogued\\nAuthors: {authors_str}\\nJournal: {journal}\\nTitle: {record['MedlineCitation']['Article']['ArticleTitle']}\\nPMID: {pmid}\\nAbstract: {abstract}\\n\\n\"    \n",
        "                        out_string2 = f\"{pub_date_str1} -DatePublished\\n{pub_date_str}  -DateCatalogued\\nTitle: {record['MedlineCitation']['Article']['ArticleTitle']}\"\n",
        "                    if Date1 > Date0:\n",
        "                        out_string = f\"{pub_date_str}  -DateCatalogued\\n{pub_date_str1} -DatePublished\\nAuthors: {authors_str}\\nJournal: {journal}\\nTitle: {record['MedlineCitation']['Article']['ArticleTitle']}\\nPMID: {pmid}\\nAbstract: {abstract}\\n\\n\"\n",
        "                        out_string2 = f\"{pub_date_str}  -DateCatalogued\\n{pub_date_str1} -DatePublished\\nTitle: {record['MedlineCitation']['Article']['ArticleTitle']}\"\n",
        "            else:\n",
        "                out_string = f\"{pub_date_str}  -DateCatalogued\\n{pub_date_str1} -DatePublished\\nAuthors: {authors_str}\\nJournal: {journal}\\nTitle: {record['MedlineCitation']['Article']['ArticleTitle']}\\nPMID: {pmid}\\nAbstract: {abstract}\\n\\n\"\n",
        "                out_string2 = f\"{pub_date_str}  -DateCatalogued\\n{pub_date_str1} -DatePublished\\nTitle: {record['MedlineCitation']['Article']['ArticleTitle']}\"\n",
        "            if skipme==0:\n",
        "                abstracts_with_info.append(out_string)\n",
        "                article_title.append(out_string2)\n",
        "\n",
        "\n",
        "        time.sleep(1) # Add a delay of 1 second\n",
        "    else:\n",
        "        print('No results found for this group.')\n",
        "\n",
        "# Sort abstracts by date\n",
        "abstracts_with_info.sort(reverse=True)\n",
        "article_title.sort(reverse=True)\n",
        "\n",
        "# Create subfolder if it doesn't exist\n",
        "#if not os.path.exists(\"phyto_results\"):\n",
        "    #os.mkdir(\"phyto_results\")\n",
        "\n",
        "# Get current time to name output file\n",
        "user_query = re.sub(r'[^a-zA-Z0-9]+', '_', user_query)\n",
        "now = datetime.datetime.now()\n",
        "\n",
        "#output_file_name = f\"phyto_results/{user_query}_{now.strftime('%Y%m%d_%H%M%S')}.txt\"\n",
        "# experimental save file to Google Drive\n",
        "output_file_name = f\"drive/MyDrive/plant_search_text_files/saved_searches/{choice}_{user_query}_{now.strftime('%Y%m%d_%H%M%S')}.txt\"\n",
        "title_file_name = f\"drive/MyDrive/plant_search_text_files/titles_only/Titles_only_{choice}_{user_query}_{now.strftime('%Y%m%d_%H%M%S')}.txt\"\n",
        "pubmed_query = f\"drive/MyDrive/plant_search_text_files/query_files/query_file_{choice}_{user_query}_{now.strftime('%Y%m%d_%H%M%S')}.txt\"\n",
        "\n",
        "# Merge all abstracts into one file, sorted by date\n",
        "with open(output_file_name, 'w', encoding='utf-8') as out_file, \\\n",
        "     open(pubmed_query, 'w', encoding='utf-8') as query_file, \\\n",
        "     open(title_file_name, 'w', encoding='utf-8') as title_file:\n",
        "    query_file.write(query_terms + '\\n')\n",
        "    count_papers = 1\n",
        "    total_length = len(abstracts_with_info)\n",
        "    out_file.write(str(total_length) + ' papers are in this text file \\n' )\n",
        "    for abstract in abstracts_with_info:\n",
        "        out_file.write('Paper #' + str(count_papers) + ' - ')\n",
        "        count_papers += 1\n",
        "        out_file.write(abstract)\n",
        "    count_titles = 1\n",
        "    title_file.write(str(total_length) + ' papers are in this text file \\n' )\n",
        "    for title in article_title:\n",
        "        title_file.write('\\n\\nPaper #' + str(count_titles) + ' - ')\n",
        "        count_titles += 1\n",
        "        title_file.write(title)\n",
        "\n",
        "        \n",
        "\n",
        "# Empty the input_files folder\n",
        "for file_name in os.listdir('input_files'):\n",
        "    file_path = os.path.join('input_files', file_name)\n",
        "    try:\n",
        "        os.remove(file_path)\n",
        "    except:\n",
        "        print(f'Error deleting {file_path}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jg425fwdWLow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTWTjsrZJGyZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "x76S5KVkoJbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd893ff-c290-4652-cc95-cfe85653b31c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Bio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDpKxoSC9G88",
        "outputId": "76cb06d6-840c-4a7d-e442-1d061ea27672"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Bio in /usr/local/lib/python3.9/dist-packages (1.5.6)\n",
            "Requirement already satisfied: mygene in /usr/local/lib/python3.9/dist-packages (from Bio) (3.2.2)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.9/dist-packages (from Bio) (1.7.0)\n",
            "Requirement already satisfied: gprofiler-official in /usr/local/lib/python3.9/dist-packages (from Bio) (1.0.0)\n",
            "Requirement already satisfied: biopython>=1.80 in /usr/local/lib/python3.9/dist-packages (from Bio) (1.81)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from Bio) (2.25.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from Bio) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from Bio) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from biopython>=1.80->Bio) (1.22.4)\n",
            "Requirement already satisfied: biothings-client>=0.2.6 in /usr/local/lib/python3.9/dist-packages (from mygene->Bio) (0.2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/dist-packages (from pandas->Bio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas->Bio) (2022.7.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.9/dist-packages (from pooch->Bio) (3.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from pooch->Bio) (23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->Bio) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->Bio) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->Bio) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->Bio) (4.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7.3->pandas->Bio) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#experimental trying to make choice 3 work\n",
        "#experimental run from drive \n",
        "\n",
        "\n",
        "from Bio import Entrez\n",
        "import datetime\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "from http.client import IncompleteRead\n",
        "\n",
        "email = input('What is your email address?')\n",
        "# Email address is required by NCBI\n",
        "Entrez.email = email\n",
        "\n",
        "# Choose which txt files to search over\n",
        "choice = input('Do you want to search over all plant genera (enter 1) | all phytochemicals (enter 2) | or both (enter 3) |\\\n",
        "                If you do not want to search over plants or phytochemicals, \\\n",
        "                try searching over human genes first (not as good as MESH term search) (enter 4) : ')\n",
        "choice = int(choice)\n",
        "\n",
        "# Load correct text file\n",
        "if choice == 1:\n",
        "    with open('drive/MyDrive/plant_search_text_files/genus_names2.txt', 'r') as f:\n",
        "        genus_names = f.read().split('@')\n",
        "if choice == 2:\n",
        "    with open('drive/MyDrive/plant_search_text_files/phytochem3.txt', 'r') as f:\n",
        "        genus_names = f.read().split('\\t')\n",
        "       \n",
        "if choice == 3:\n",
        "    with open('drive/MyDrive/plant_search_text_files/genus_names2.txt', 'r') as f:\n",
        "        genus_names = f.read().split('@')\n",
        "    with open('drive/MyDrive/plant_search_text_files/phytochem3.txt', 'r') as f:\n",
        "        phyt_names = f.read().split('\\t')\n",
        "\n",
        "if choice == 4:\n",
        "    with open('drive/MyDrive/plant_search_text_files/gene1.txt', 'r') as f:\n",
        "        genus_names = f.read().split('@')\n",
        "\n",
        "\n",
        "# User-defined search term\n",
        "user_query = input('Enter additional non-plant search terms: ')\n",
        "\n",
        "# Set counter in case choice == 3. This allows first 38 searches to include \"plant\" as a key word\n",
        "gen_phyt_counter = 1\n",
        "\n",
        "# Create directory for input files if it doesn't exist\n",
        "if not os.path.exists('input_files'):\n",
        "    os.makedirs('input_files')\n",
        "\n",
        "# Split the genus names into groups of 1000 or less, to stay under the PubMed search limit\n",
        "genus_groups = [genus_names[i:i+1000] for i in range(0, len(genus_names), 1000)]\n",
        "\n",
        "if choice == 3:\n",
        "    genus_groups = [genus_names[i:i+1000] for i in range(0, len(genus_names), 1000)]\n",
        "    phyt_groups = [phyt_names[i:i+1000] for i in range(0, len(phyt_names), 1000)]\n",
        "\n",
        "    genus_groups = genus_groups + phyt_groups\n",
        "   \n",
        "\n",
        "\n",
        "# List to store abstracts and their associated date information\n",
        "abstracts_with_info = []\n",
        "\n",
        "# Set to keep track of seen Pubmed IDs\n",
        "seen_pmids = set()\n",
        "\n",
        "for i, genus_group in enumerate(genus_groups):\n",
        "    # Construct query string\n",
        "    if choice == 1: \n",
        "        query_terms = '(' + ' OR '.join(genus_group) + ') + AND \"plant\" AND ' + user_query\n",
        "    if choice == 3: \n",
        "        if gen_phyt_counter <= 38:\n",
        "            query_terms = '(' + ' OR '.join(genus_group) + ') + AND \"plant\" AND ' + user_query\n",
        "        if gen_phyt_counter > 38:\n",
        "            query_terms = '(' + ' OR '.join(genus_group) + ') + AND ' + user_query \n",
        "    if choice == 2: \n",
        "        query_terms = '(' + ' OR '.join(genus_group) + ') + AND ' + user_query \n",
        "    if choice == 4: \n",
        "        query_terms = '(' + ' OR '.join(genus_group) + ') + AND ' + user_query\n",
        "    \n",
        "    gen_phyt_counter += 1\n",
        "    \n",
        "    # # # testing line, remove\n",
        "    # if gen_phyt_counter == 38:\n",
        "    #     print(query_terms)\n",
        "    # if gen_phyt_counter == 39:\n",
        "    #     print(query_terms)\n",
        "    # if gen_phyt_counter == 40:\n",
        "    #     print(query_terms)\n",
        "\n",
        "\n",
        "    # Print search query\n",
        "    print(f'Searching group {i+1}/{len(genus_groups)}')\n",
        "\n",
        "    \n",
        "    # Perform search\n",
        "    try:\n",
        "        handle = Entrez.esearch(db='pubmed', term=query_terms, retmax=100000)\n",
        "        record = Entrez.read(handle)\n",
        "        handle.close()\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\", str(e))\n",
        "        \n",
        "\n",
        "    # Fetch abstracts for all search results\n",
        "    id_list = record['IdList']\n",
        "    \n",
        "    query_numb = 1\n",
        "    exc = 1\n",
        "    \n",
        "    if id_list:\n",
        "      while exc == 1:\n",
        "        try:\n",
        "          print(f'Fetching {len(id_list)} abstracts...')\n",
        "          handle = Entrez.efetch(db='pubmed', id=id_list, retmode='xml')\n",
        "          records = Entrez.read(handle)\n",
        "          handle.close()\n",
        "          exc = 0\n",
        "        except IncompleteRead:\n",
        "          query_numb += 1\n",
        "          if query_numb == 5:\n",
        "            raise Exception('Failed to fetch abstracts after 5 attempts.')\n",
        "          print(f'Error fetching abstracts, retrying ({query_numb}/5)...')\n",
        "          time.sleep(5) # Wait 5 seconds before retrying\n",
        "          exc = 1\n",
        "          \n",
        "          \n",
        "          \n",
        "\n",
        "    # def fetch_abstracts(id_list):\n",
        "    #   for i in range(5): # Try up to 5 times\n",
        "    #       try:\n",
        "    #           print(f'Fetching {len(id_list)} abstracts...')\n",
        "    #           handle = Entrez.efetch(db='pubmed', id=id_list, retmode='xml')\n",
        "    #           records = Entrez.read(handle)\n",
        "    #           handle.close()\n",
        "    #           return records\n",
        "    #       except IncompleteRead:\n",
        "    #           print(f'Error fetching abstracts, retrying ({i+1}/5)...')\n",
        "    #           time.sleep(5) # Wait 5 seconds before retrying\n",
        "    #           raise Exception('Failed to fetch abstracts after 5 attempts.')\n",
        "\n",
        "    # fetch_abstracts(id_list)\n",
        "\n",
        "        # Extract abstracts and date information for each record\n",
        "        for record in records['PubmedArticle']:\n",
        "            try:\n",
        "                abstract = record['MedlineCitation']['Article']['Abstract']['AbstractText'][0]\n",
        "            except (KeyError, IndexError):\n",
        "                abstract = 'Not available'\n",
        "            #EntrezDate\n",
        "            try:\n",
        "                pub_date = record['MedlineCitation']['DateRevised']\n",
        "                pub_date_str = f\"{pub_date.get('Year', 'Not available')}-{pub_date.get('Month', 'Not available')}-{pub_date.get('Day', 'Not available')}\"\n",
        "            except KeyError:\n",
        "                pub_date_str = 'Not available'\n",
        "            #PubDate\n",
        "            try:\n",
        "                pub_date1 = record['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']\n",
        "                pub_date_str1 = f\"{pub_date1.get('Year', 'Not available')} {pub_date1.get('Month', 'Not available')}\"\n",
        "            except KeyError:\n",
        "                pub_date_str1 = 'Not available'\n",
        "            try:\n",
        "                journal = record['MedlineCitation']['Article']['Journal']['Title']\n",
        "            except KeyError:\n",
        "                journal = 'Not available'\n",
        "            try:\n",
        "                authors = record['MedlineCitation']['Article']['AuthorList']\n",
        "                author_names = [f\"{author.get('LastName', 'Not available')}, {author.get('ForeName', '')}\" for author in authors]\n",
        "                authors_str = ', '.join(author_names)\n",
        "            except KeyError:\n",
        "                authors_str = 'Not available'\n",
        "            try:\n",
        "                pmid = record['MedlineCitation']['PMID']\n",
        "            except KeyError:\n",
        "                pmid = 'Not available'\n",
        "            \n",
        "            #Add new PubMed ID to set\n",
        "            skipme=1\n",
        "            if pmid not in seen_pmids:\n",
        "                seen_pmids.add(pmid)\n",
        "                skipme=0\n",
        "\n",
        "\n",
        "            Date1 = pub_date_str1[0:4]\n",
        "            Date0 = pub_date_str[0:4]\n",
        "\n",
        "            \n",
        "\n",
        "            if Date1 != Date0:\n",
        "                if \"Not\" in Date1:\n",
        "                    out_string = f\"{pub_date_str}  -DateCatalogued\\n{pub_date_str1} -DatePublished\\nAuthors: {authors_str}\\nJournal: {journal}\\nTitle: {record['MedlineCitation']['Article']['ArticleTitle']}\\nPMID: {pmid}\\nAbstract: {abstract}\\n\\n\"\n",
        "                else:\n",
        "                    if Date1 < Date0:\n",
        "                        out_string = f\"{pub_date_str1} -DatePublished\\n{pub_date_str}  -DateCatalogued\\nAuthors: {authors_str}\\nJournal: {journal}\\nTitle: {record['MedlineCitation']['Article']['ArticleTitle']}\\nPMID: {pmid}\\nAbstract: {abstract}\\n\\n\"    \n",
        "                    if Date1 > Date0:\n",
        "                        out_string = f\"{pub_date_str}  -DateCatalogued\\n{pub_date_str1} -DatePublished\\nAuthors: {authors_str}\\nJournal: {journal}\\nTitle: {record['MedlineCitation']['Article']['ArticleTitle']}\\nPMID: {pmid}\\nAbstract: {abstract}\\n\\n\"\n",
        "            else:\n",
        "                out_string = f\"{pub_date_str}  -DateCatalogued\\n{pub_date_str1} -DatePublished\\nAuthors: {authors_str}\\nJournal: {journal}\\nTitle: {record['MedlineCitation']['Article']['ArticleTitle']}\\nPMID: {pmid}\\nAbstract: {abstract}\\n\\n\"\n",
        "            \n",
        "            if skipme==0:\n",
        "                abstracts_with_info.append(out_string)\n",
        "\n",
        "\n",
        "        time.sleep(1) # Add a delay of 1 second\n",
        "    else:\n",
        "        print('No results found for this group.')\n",
        "\n",
        "# Sort abstracts by date\n",
        "abstracts_with_info.sort(reverse=True)\n",
        "\n",
        "# Create subfolder if it doesn't exist\n",
        "if not os.path.exists(\"phyto_results\"):\n",
        "    os.mkdir(\"phyto_results\")\n",
        "\n",
        "# Get current time to name output file\n",
        "user_query = re.sub(r'[^a-zA-Z0-9]+', '_', user_query)\n",
        "now = datetime.datetime.now()\n",
        "\n",
        "#output_file_name = f\"phyto_results/{user_query}_{now.strftime('%Y%m%d_%H%M%S')}.txt\"\n",
        "# experimental save file to Google Drive\n",
        "output_file_name = f\"drive/MyDrive/plant_search_text_files/saved_searches/{choice}_{user_query}_{now.strftime('%Y%m%d_%H%M%S')}.txt\"\n",
        "\n",
        "# Merge all abstracts into one file, sorted by date\n",
        "with open(output_file_name, 'w', encoding='utf-8') as out_file, \\\n",
        "     open('pubmed_query.txt', 'w', encoding='utf-8') as query_file:\n",
        "    query_file.write(query_terms + '\\n')\n",
        "    for abstract in abstracts_with_info:\n",
        "        out_file.write(abstract)\n",
        "\n",
        "# Empty the input_files folder\n",
        "for file_name in os.listdir('input_files'):\n",
        "    file_path = os.path.join('input_files', file_name)\n",
        "    try:\n",
        "        os.remove(file_path)\n",
        "    except:\n",
        "        print(f'Error deleting {file_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg425fwdWLow",
        "outputId": "7ea90421-afa0-4771-8099-0162e86ff955"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is your email address?bclarky12@gmail.com\n",
            "Do you want to search over all plant genera (enter 1) | all phytochemicals (enter 2) | or both (enter 3) |                If you do not want to search over plants or phytochemicals,                 try searching over human genes first (not as good as MESH term search) (enter 4) : 1\n",
            "Enter additional non-plant search terms: alox5\n",
            "Searching group 1/38\n",
            "Fetching 4 abstracts...\n",
            "Searching group 2/38\n",
            "Fetching 3 abstracts...\n",
            "Searching group 3/38\n",
            "Fetching 2 abstracts...\n",
            "Searching group 4/38\n",
            "Fetching 3 abstracts...\n",
            "Searching group 5/38\n",
            "Fetching 3 abstracts...\n",
            "Searching group 6/38\n",
            "Fetching 2 abstracts...\n",
            "Searching group 7/38\n",
            "Fetching 4 abstracts...\n",
            "Searching group 8/38\n",
            "Fetching 2 abstracts...\n",
            "Searching group 9/38\n",
            "Fetching 3 abstracts...\n",
            "Searching group 10/38\n",
            "Fetching 3 abstracts...\n",
            "Searching group 11/38\n",
            "No results found for this group.\n",
            "Searching group 12/38\n",
            "Fetching 2 abstracts...\n",
            "Searching group 13/38\n",
            "Fetching 12 abstracts...\n",
            "Searching group 14/38\n",
            "Fetching 5 abstracts...\n",
            "Searching group 15/38\n",
            "Fetching 2 abstracts...\n",
            "Searching group 16/38\n",
            "Fetching 1 abstracts...\n",
            "Searching group 17/38\n",
            "Fetching 1 abstracts...\n",
            "Searching group 18/38\n",
            "Fetching 6 abstracts...\n",
            "Searching group 19/38\n",
            "Fetching 2 abstracts...\n",
            "Searching group 20/38\n",
            "Fetching 1 abstracts...\n",
            "Searching group 21/38\n",
            "Fetching 2 abstracts...\n",
            "Searching group 22/38\n",
            "Fetching 4 abstracts...\n",
            "Searching group 23/38\n",
            "Fetching 1 abstracts...\n",
            "Searching group 24/38\n",
            "Fetching 1 abstracts...\n",
            "Searching group 25/38\n",
            "Fetching 1 abstracts...\n",
            "Searching group 26/38\n",
            "No results found for this group.\n",
            "Searching group 27/38\n",
            "Fetching 3 abstracts...\n",
            "Searching group 28/38\n",
            "Fetching 2 abstracts...\n",
            "Searching group 29/38\n",
            "Fetching 1 abstracts...\n",
            "Searching group 30/38\n",
            "Fetching 3 abstracts...\n",
            "Searching group 31/38\n",
            "Fetching 2 abstracts...\n",
            "Searching group 32/38\n",
            "Fetching 4 abstracts...\n",
            "Searching group 33/38\n",
            "Fetching 1 abstracts...\n",
            "Searching group 34/38\n",
            "Fetching 2 abstracts...\n",
            "Searching group 35/38\n",
            "Fetching 1 abstracts...\n",
            "Searching group 36/38\n",
            "Fetching 2 abstracts...\n",
            "Searching group 37/38\n",
            "Fetching 3 abstracts...\n",
            "Searching group 38/38\n",
            "Fetching 1 abstracts...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n8LZ1dMJsd06"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}